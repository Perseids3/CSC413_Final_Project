{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHiGdD6INLfv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xlrd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jester_data(file_path, delimiter='\\t', valfrac=0.1, random_state=1234):\n",
        "    data = pd.read_excel(file_path, header=None)\n",
        "    data = data.replace(99, 0)  # Replace \"99\" (not rated) with \"0\"\n",
        "    \n",
        "    train_data, validation_data = train_test_split(data, test_size=valfrac, random_state=random_state)\n",
        "    train_data, validation_data = train_data.values, validation_data.values\n",
        "    \n",
        "    return train_data, validation_data\n",
        "\n",
        "# Load Jester dataset\n",
        "file_path = 'jester-data-1.xls'\n",
        "train_data, validation_data = load_jester_data(file_path)"
      ],
      "metadata": {
        "id": "HV7SdRISPRjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "0VQ5AG__SxGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = int(time())\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n"
      ],
      "metadata": {
        "id": "re2xGFToSweL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a4e87b-1ff1-40df-88e1-01add5a97733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbd5b7abb50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_users, n_jokes = train_data.shape\n",
        "n_hid = 800\n",
        "n_layers = 2\n",
        "lambda_s = 1e-3\n",
        "lambda_2 = 1e-3\n",
        "output_every = 50\n",
        "n_epoch = n_layers * 10 * output_every\n",
        "\n",
        "\n",
        "verbose_bfgs = True\n",
        "use_gpu = True\n",
        "\n",
        "if use_gpu and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "mX99sgJgdvA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KernelLayer(nn.Module):\n",
        "    def __init__(self, n_in, n_hid=800, n_dim=5, activation=nn.ReLU(),\n",
        "                 lambda_s=lambda_s, lambda_2=lambda_2, dropout_p=0.5):\n",
        "        super(KernelLayer, self).__init__()\n",
        "\n",
        "        self.W = nn.Parameter(torch.empty(n_in, n_hid).normal_(std=1e-3))\n",
        "        self.u = nn.Parameter(torch.empty(n_in, 1, n_dim).normal_(std=1e-3))\n",
        "        self.v = nn.Parameter(torch.empty(1, n_hid, n_dim).normal_(std=1e-3))\n",
        "        self.b = nn.Parameter(torch.zeros(n_hid))\n",
        "        self.activation = activation\n",
        "        self.batch_norm = nn.BatchNorm1d(n_hid)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.lambda_s = lambda_s\n",
        "        self.lambda_2 = lambda_2\n",
        "\n",
        "    def kernel(self, u, v):\n",
        "        dist = torch.norm(u - v, p=2, dim=2)\n",
        "        hat = torch.clamp(1.0 - dist ** 2, 0.0)\n",
        "        return hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        w_hat = self.kernel(self.u, self.v)\n",
        "        W_eff = self.W * w_hat\n",
        "        y = x @ W_eff + self.b\n",
        "        y = self.batch_norm(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.dropout(y)\n",
        "        return y\n",
        "\n",
        "    def regularization(self):\n",
        "        w_hat = self.kernel(self.u, self.v)\n",
        "        sparse_reg_term = self.lambda_s * torch.norm(w_hat, p=2)\n",
        "        l2_reg_term = self.lambda_2 * torch.norm(self.W, p=2)\n",
        "        return sparse_reg_term + l2_reg_term\n"
      ],
      "metadata": {
        "id": "soWG0X4zSpO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KernelNet(nn.Module):\n",
        "    def __init__(self, n_u, n_hid, n_layers, lambda_s, lambda_2):\n",
        "        super(KernelNet, self).__init__()\n",
        "\n",
        "        # Create the hidden layers and output layer using KernelLayer class\n",
        "        layers = [KernelLayer(n_u if i == 0 else n_hid, n_hid, lambda_s=lambda_s, lambda_2=lambda_2)\n",
        "                  for i in range(n_layers)]\n",
        "        layers.append(KernelLayer(n_hid, n_u, activation=nn.Identity(), lambda_s=lambda_s, lambda_2=lambda_2))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through all the layers in the network\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization(self):\n",
        "        # Compute the regularization loss for the entire network\n",
        "        reg_losses = sum(layer.regularization() for layer in self.layers)\n",
        "        return reg_losses\n",
        "\n"
      ],
      "metadata": {
        "id": "n0wyBLUNb2pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparse_matrix(data):\n",
        "    n_users, n_items = data.shape\n",
        "    ratings = np.zeros((n_users, n_items))\n",
        "    \n",
        "    for i in range(n_users):\n",
        "        for j in range(n_items):\n",
        "            rating = data[i, j]\n",
        "            if rating != 0:\n",
        "                ratings[i, j] = rating\n",
        "\n",
        "    return ratings\n"
      ],
      "metadata": {
        "id": "ln0ZcMSkcIj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(ratings):\n",
        "    ratings = torch.tensor(ratings, dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "    non_zero_ratings_mask = ratings != 0\n",
        "    mean_ratings = (ratings * non_zero_ratings_mask).sum(axis=1) / non_zero_ratings_mask.sum(axis=1)\n",
        "    mean_ratings = mean_ratings.unsqueeze(1)  # Add a dimension for broadcasting\n",
        "    normalized_ratings = ratings.where(non_zero_ratings_mask, torch.zeros_like(ratings)) - mean_ratings * non_zero_ratings_mask\n",
        "    return normalized_ratings, mean_ratings\n"
      ],
      "metadata": {
        "id": "SiFi5563cKv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, tr, vr, n_epoch, output_every, device, tr_mean, vr_mean, num_users_sample=1000):\n",
        "    tr = tr.float().to(device)\n",
        "    vr = vr.float().to(device)\n",
        "\n",
        "    tm = (tr != 0).float().to(device)  # Create mask for train data\n",
        "    vm = (vr != 0).float().to(device)  # Create mask for validation data\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.LBFGS(model.parameters(), lr=0.01, max_iter=output_every)\n",
        "\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(tr)\n",
        "        diff = tm * (tr - prediction)\n",
        "        sqE = torch.norm(diff, p=2)\n",
        "        loss = sqE + model.regularization()\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    for i in range(int(n_epoch / output_every)):\n",
        "        optimizer.step(closure)\n",
        "        with torch.no_grad():\n",
        "            tr_prediction = model(tr)\n",
        "            tr_prediction += tr_mean  # Add the mean rating back\n",
        "\n",
        "            # Select a random subset of users for validation\n",
        "            user_indices = np.random.choice(vr.shape[0], num_users_sample, replace=False)\n",
        "            user_indices = torch.tensor(user_indices, dtype=torch.long, device=device)  # Convert to PyTorch tensor\n",
        "            vr_sub = vr[user_indices]\n",
        "            vm_sub = vm[user_indices]\n",
        "            \n",
        "            vr_prediction = model(vr_sub)\n",
        "            vr_prediction += vr_mean[user_indices].expand(-1, vr_prediction.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            error = ((vm_sub * (torch.clamp(vr_prediction, -10., 10.) - vr_sub) ** 2).sum() / vm_sub.sum()).sqrt().item()\n",
        "            error_train = ((tm * (torch.clamp(tr_prediction, -10., 10.) - tr) ** 2).sum() / tm.sum()).sqrt().item()\n",
        "\n",
        "            print('.-^-._' * 12)\n",
        "            print('epoch:', i, 'validation rmse:', error, 'train rmse:', error_train)\n",
        "            print('.-^-._' * 12)\n"
      ],
      "metadata": {
        "id": "Vhb3slRucNEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tr = create_sparse_matrix(train_data)\n",
        "# vr = create_sparse_matrix(validation_data)\n",
        "\n",
        "tr, tr_mean = normalize_data(train_data)\n",
        "vr, vr_mean = normalize_data(validation_data)\n",
        "\n",
        "\n",
        "tr = tr.clone().detach().to(device)\n",
        "vr = vr.clone().detach().to(device)\n",
        "tr_mean = tr_mean.clone().detach().to(device)\n",
        "vr_mean = vr_mean.clone().detach().to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = KernelNet(n_jokes, n_hid, n_layers, lambda_s, lambda_2)\n",
        "\n",
        "train(model, tr, vr, n_epoch, output_every, device, tr_mean, vr_mean, num_users_sample=1000)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCiwLmuOcPMe",
        "outputId": "d0fd22ea-5955-4b89-8c72-d3b83994a0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 0 validation rmse: 10.33069896697998 train rmse: 10.337873458862305\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 1 validation rmse: 10.325453758239746 train rmse: 10.280762672424316\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 2 validation rmse: 10.245012283325195 train rmse: 10.1530122756958\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 3 validation rmse: 10.178176879882812 train rmse: 10.121927261352539\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 4 validation rmse: 10.13007926940918 train rmse: 10.11397647857666\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 5 validation rmse: 10.101311683654785 train rmse: 10.097795486450195\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 6 validation rmse: 10.117122650146484 train rmse: 10.071925163269043\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 7 validation rmse: 10.169245719909668 train rmse: 10.06092357635498\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 8 validation rmse: 10.104445457458496 train rmse: 10.049483299255371\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 9 validation rmse: 10.049542427062988 train rmse: 10.047592163085938\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 10 validation rmse: 10.038704872131348 train rmse: 10.046586036682129\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 11 validation rmse: 10.065595626831055 train rmse: 10.047780990600586\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 12 validation rmse: 10.010719299316406 train rmse: 10.028144836425781\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 13 validation rmse: 9.816781044006348 train rmse: 9.782090187072754\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 14 validation rmse: 9.765851974487305 train rmse: 9.732267379760742\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 15 validation rmse: 9.74321174621582 train rmse: 9.731447219848633\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 16 validation rmse: 9.688602447509766 train rmse: 9.713152885437012\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 17 validation rmse: 9.809536933898926 train rmse: 9.732022285461426\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 18 validation rmse: 9.770147323608398 train rmse: 9.7208890914917\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "epoch: 19 validation rmse: 9.759379386901855 train rmse: 9.717731475830078\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"
          ]
        }
      ]
    }
  ]
}